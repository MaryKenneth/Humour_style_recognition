{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from data_preprocessing import lemmatize_text_with_pos, tokens,lemmatize_spacy\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions/Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read a single Dataset File\n",
    "def read_dataset(file_path):\n",
    "    if file_path.lower().endswith('.csv'):\n",
    "        dataset = pd.read_csv(file_path)\n",
    "    elif file_path.lower().endswith('.xlsx'):\n",
    "        dataset = pd.read_excel(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please provide a .csv or .xlsx file.\")\n",
    "    \n",
    "    dataset   = np.array(dataset)\n",
    "    data_train, data_test     = train_test_split(dataset, test_size=0.2, random_state=100)\n",
    "\n",
    "    x_train, y_train   = (data_train[:,:-1]), (data_train[:,-1]).astype(\"int32\")\n",
    "    x_test, y_test     = (data_test[:,:-1]), (data_test[:,-1]).astype(\"int32\")           \n",
    "    x_train, x_test    = x_train.squeeze(), x_test.squeeze()\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "# If you have Train and Test Datasets separate\n",
    "def read_train_test_dataset(train_data, test_data):\n",
    "    if train_data.lower().endswith('.csv') and test_data.lower().endswith('.csv'):\n",
    "        train_data = pd.read_csv(train_data)\n",
    "        test_data = pd.read_csv(test_data)\n",
    "    elif train_data.lower().endswith('.xlsx') and test_data.lower().endswith('.xlsx'):\n",
    "        train_data = pd.read_excel(train_data)\n",
    "        test_data = pd.read_excel(test_data)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please provide a .csv or .xlsx file.\")\n",
    "    \n",
    "    train_data, test_data   = np.array(train_data), np.array(test_data)\n",
    "\n",
    "    x_train, y_train   = (train_data[:,:-1]), (train_data[:,-1]).astype(\"int32\")\n",
    "    x_test, y_test     = (test_data[:,:-1]), (test_data[:,-1]).astype(\"int32\")           \n",
    "    x_train, x_test    = x_train.squeeze(), x_test.squeeze()\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "# Example usage:\n",
    "#file_path = \"datasets/Humour_style.xlsx\" \n",
    "#train_path = \"datasets/af_ag_train.xlsx\" \n",
    "#test_path  =  \"datasets/af_ag_test.xlsx\" \n",
    "#print(read_dataset(file_path))\n",
    "#print(read_train_test_dataset(train_path,test_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vocabulary Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab(x):\n",
    "    all_word = set()\n",
    "    for i in x:\n",
    "        all_word.update(tokens(i))\n",
    "    return all_word\n",
    "\n",
    "# Example usage\n",
    "#print(len(vocab(x_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_multi(x, y, smoothing=1):\n",
    "    classes = np.unique(y)\n",
    "    vocabulary = vocab(x)\n",
    "    N_doc = x.shape[0]\n",
    "\n",
    "    log_probs = {}\n",
    "    ex_dics = {}\n",
    "    prob_words = {}\n",
    "\n",
    "    for class_label in classes:\n",
    "        N_cat = sum(y == class_label)\n",
    "        examples = \" \".join(x[y == class_label])\n",
    "\n",
    "        log_prob = np.log(N_cat / N_doc)\n",
    "        log_probs[class_label] = log_prob\n",
    "\n",
    "        ex_dic = {}\n",
    "        prob_word = {}\n",
    "\n",
    "        for word in vocabulary:\n",
    "            escaped_word = re.escape(word)\n",
    "\n",
    "            word_count = len(re.findall(escaped_word, examples))\n",
    "            ex_dic[word] = word_count\n",
    "\n",
    "            prob_word[word] = np.round(np.log((word_count + smoothing) / (len(tokens(examples)) + len(vocabulary))), 5)\n",
    "\n",
    "        ex_dics[class_label] = ex_dic\n",
    "        prob_words[class_label] = prob_word\n",
    "\n",
    "    return log_probs, ex_dics, prob_words\n",
    "\n",
    "# Example usage\n",
    "#log_probs, ex_dics, prob_words = naive_bayes_multi(x_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_naive_bayes(examples, log_probs, prob_words):\n",
    "    predictions = []\n",
    "\n",
    "    for example in examples:\n",
    "        # Tokenize the example\n",
    "        example_tokens = tokens(example)\n",
    "\n",
    "        # Calculate the log likelihoods for each class\n",
    "        class_likelihoods = {}\n",
    "        for class_label, log_prob in log_probs.items():\n",
    "            class_likelihood = log_prob + sum(prob_words[class_label].get(word, 0) for word in example_tokens)\n",
    "            class_likelihoods[class_label] = class_likelihood\n",
    "\n",
    "        # Make a prediction based on the class with the highest likelihood\n",
    "        prediction = max(class_likelihoods, key=class_likelihoods.get)\n",
    "        predictions.append(prediction)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "#example usage\n",
    "#log_probs, ex_dics, prob_words = naive_bayes_multi(x_train, y_train)\n",
    "#predicted_labels = predict_naive_bayes(x_test, log_probs, prob_words)\n",
    "\n",
    "# Evaluation Report\n",
    "#report = classification_report(y_test,predicted_labels)\n",
    "#print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Reports Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results(true_label, predicted):\n",
    "    report_dict = classification_report(true_label,predicted,output_dict=True)\n",
    "\n",
    "    # Save Result Report\n",
    "    save_report = pd.DataFrame(report_dict).transpose()  # Convert the report dictionary to a DataFrame\n",
    "    save_report = save_report.round(3)                   # Round the values to a specific number of decimal places\n",
    "    save_report = save_report.astype({'support': int})   # Convert the 'support' column to integers\n",
    "    save_report.loc['accuracy', ['precision', 'recall', 'support']] = [None, None, None] # Set the accuracy row to None\n",
    "\n",
    "    return save_report\n",
    "\n",
    "# Example Usage \n",
    "#save_report = save_results(y_test,predicted_labels)\n",
    "#save_report.to_csv('models_results/Naive_Bayes_5classes.csv', index=False)  # Save the DataFrame to a CSV file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Five Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.85      0.76        59\n",
      "           1       0.66      0.65      0.65        48\n",
      "           2       0.60      0.41      0.49        44\n",
      "           3       0.57      0.74      0.64        46\n",
      "           4       1.00      0.79      0.88        56\n",
      "\n",
      "    accuracy                           0.70       253\n",
      "   macro avg       0.70      0.69      0.68       253\n",
      "weighted avg       0.72      0.70      0.70       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read dataset \n",
    "humor_5class_path = \"datasets/Humour_style.xlsx\" \n",
    "x_train_5, x_test_5, y_train_5, y_test_5 = read_dataset(humor_5class_path)\n",
    "\n",
    "# Lemmmatize (Spacy)\n",
    "x_train_5 = [' '.join(lemmatize_spacy(example)) for example in x_train_5]\n",
    "x_test_5  = [' '.join(lemmatize_spacy(example)) for example in x_test_5]\n",
    "\n",
    "# Convert to numpy array\n",
    "x_train_5, x_test_5 = np.array(x_train_5), np.array(x_test_5)\n",
    "\n",
    "# Train Naive Bayes Model\n",
    "log_probs_5, ex_dics_5, prob_words_5 = naive_bayes_multi(x_train_5,y_train_5)\n",
    "\n",
    "# Test/Predict using Naive Bayes Model\n",
    "predicted_labels_5 = predict_naive_bayes(x_test_5, log_probs_5, prob_words_5)\n",
    "\n",
    "# Save Report\n",
    "result_5= save_results(y_test_5,predicted_labels_5)\n",
    "result_5.to_csv('models_results/Naive_Bayes_5classes.csv', index=False)\n",
    "\n",
    "# Evaluation Report\n",
    "print(classification_report(y_test_5,predicted_labels_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Four Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.58      0.65        59\n",
      "           1       0.74      0.54      0.63        48\n",
      "           2       0.62      0.91      0.74        90\n",
      "           3       1.00      0.71      0.83        56\n",
      "\n",
      "    accuracy                           0.72       253\n",
      "   macro avg       0.78      0.69      0.71       253\n",
      "weighted avg       0.76      0.72      0.72       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read dataset \n",
    "humor_4class_path = \"datasets/Humour_style_4classes.xlsx\" \n",
    "x_train_4, x_test_4, y_train_4, y_test_4 = read_dataset(humor_4class_path)\n",
    "\n",
    "# Lemmmatize (Spacy)\n",
    "x_train_4 = [' '.join(lemmatize_spacy(example)) for example in x_train_4]\n",
    "x_test_4  = [' '.join(lemmatize_spacy(example)) for example in x_test_4]\n",
    "\n",
    "# Convert to numpy array\n",
    "x_train_4, x_test_4 = np.array(x_train_4), np.array(x_test_4)\n",
    "\n",
    "# Train Naive Bayes Model\n",
    "log_probs_4, ex_dics_4, prob_words_4 = naive_bayes_multi(x_train_4,y_train_4)\n",
    "\n",
    "# Test/Predict using Naive Bayes Model\n",
    "predicted_labels_4 = predict_naive_bayes(x_test_4, log_probs_4, prob_words_4)\n",
    "\n",
    "# Save Report\n",
    "result_4= save_results(y_test_4,predicted_labels_4)\n",
    "result_4.to_csv('models_results/Naive_Bayes_4classes.csv', index=False)\n",
    "\n",
    "# Evaluation Report\n",
    "print(classification_report(y_test_4,predicted_labels_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.66      0.73        44\n",
      "           1       0.73      0.87      0.79        46\n",
      "\n",
      "    accuracy                           0.77        90\n",
      "   macro avg       0.78      0.76      0.76        90\n",
      "weighted avg       0.78      0.77      0.76        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read dataset \n",
    "train_2class_path = \"datasets/af_ag_train.xlsx\" \n",
    "test_2class_path  = \"datasets/af_ag_test.xlsx\" \n",
    "\n",
    "x_train_2, x_test_2, y_train_2, y_test_2 = read_train_test_dataset(train_2class_path, test_2class_path)\n",
    "\n",
    "# Lemmmatize (Spacy)\n",
    "x_train_2 = [' '.join(lemmatize_spacy(example)) for example in x_train_2]\n",
    "x_test_2  = [' '.join(lemmatize_spacy(example)) for example in x_test_2]\n",
    "\n",
    "# Convert to numpy array\n",
    "x_train_2, x_test_2 = np.array(x_train_2), np.array(x_test_2)\n",
    "\n",
    "# Train Naive Bayes Model\n",
    "log_probs_2, ex_dics_2, prob_words_2 = naive_bayes_multi(x_train_2,y_train_2)\n",
    "\n",
    "# Test/Predict using Naive Bayes Model\n",
    "predicted_labels_2 = predict_naive_bayes(x_test_2, log_probs_2, prob_words_2)\n",
    "\n",
    "# Save Report\n",
    "result_2= save_results(y_test_2,predicted_labels_2)\n",
    "result_2.to_csv('models_results/Naive_Bayes_2classes.csv', index=False)\n",
    "\n",
    "# Evaluation Report\n",
    "print(classification_report(y_test_2,predicted_labels_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Individual Jokes Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function\n",
    "def predict_naive_bayes_single(example, log_probs, prob_words):\n",
    "    # Tokenize the example\n",
    "    example_tokens = tokens(example)\n",
    "\n",
    "    # Calculate the log likelihoods for each class\n",
    "    class_likelihoods = {}\n",
    "    for class_label, log_prob in log_probs.items():\n",
    "        class_likelihood = log_prob + sum(prob_words[class_label].get(word, 0) for word in example_tokens)\n",
    "        class_likelihoods[class_label] = class_likelihood\n",
    "\n",
    "    # Make a prediction based on the class with the highest likelihood\n",
    "    prediction = max(class_likelihoods, key=class_likelihoods.get)\n",
    "\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example usage of Single prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Input: \"What’s the smartest insect? A spelling bee!\n",
      " 5 class Model prediction : 0\n",
      " 4 class Model prediction : 2\n",
      " 2 class Model prediction : 0; (Where 0-Affiliative, 1-Aggressive)\n"
     ]
    }
   ],
   "source": [
    "# User input\n",
    "#user_input = \"I am living my best live in a cage of sadness and loneliness\"\n",
    "user_input = \"What’s the smartest insect? A spelling bee!\"\n",
    "\n",
    "# Preprocess the user input\n",
    "preprocessed_input = lemmatize_spacy(user_input)  # Replace with your actual preprocessing function\n",
    "preprocessed_input = \", \".join(preprocessed_input)\n",
    "\n",
    "# Make predictions\n",
    "user_prediction_5 = predict_naive_bayes_single(preprocessed_input, log_probs_5, prob_words_5) # class model\n",
    "user_prediction_4 = predict_naive_bayes_single(preprocessed_input, log_probs_4, prob_words_4) #4 class model\n",
    "\n",
    "user_prediction_2 = \"None\"\n",
    "if int(user_prediction_4) == 2:\n",
    "    user_prediction_2 = predict_naive_bayes_single(preprocessed_input, log_probs_2, prob_words_2) #2 class model\n",
    "\n",
    "# Print the predicted label\n",
    "print(f'User Input: \"{user_input}\\n 5 class Model prediction : {user_prediction_5}\\n 4 class Model prediction : {user_prediction_4}')\n",
    "print(f' 2 class Model prediction : {user_prediction_2}; (Where 0-Affiliative, 1-Aggressive)')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
